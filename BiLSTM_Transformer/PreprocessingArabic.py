
import time
import matplotlib.pyplot as plt
# import plotly.express as px
# import plotly.graph_objects as go
# import plotly.express as px
# from plotly.offline import init_notebook_mode, iplot
from tashaphyne.stemming import ArabicLightStemmer
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report, roc_curve, f1_score, accuracy_score, recall_score, roc_auc_score, \
    make_scorer
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score, GridSearchCV
from sklearn import metrics
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import confusion_matrix, mean_squared_error, precision_score, recall_score, f1_score
from farasa.stemmer import FarasaStemmer
import re
import emoji
# import langid
import pandas as pd
from tqdm import tqdm
import seaborn as sns
from langdetect import detect
from nltk.corpus import stopwords
from googletrans import Translator
# init_notebook_mode(connected=True)
from sklearn.feature_extraction.text import TfidfVectorizer

tqdm.pandas()
df = pd.read_csv('Train_Dataset.csv')
# print("df BEFORE duplicate", df)
# df.review_description.duplicated().sum()
# df.drop(df[df.review_description.duplicated() == True].index, axis=0, inplace=True)
# # print("df after duplicate", df)
#
# df = df.rename({'rating(1 postive 0 neutral -1 negative': 'label'}, axis=1)
# # df['rating'] = df['rating'].replace({-1: 'negative', 0: 'neutral', 1: 'positive'})
# # print("After target renaming", df)
#
# df.review_description = df.review_description.astype(str)
# df.review_description = df.review_description.progress_apply(
#     lambda x: re.sub('[%s]' % re.escape("""!"#$%&'()*+,ØŒ-./:;<=>ØŸ?@[\]^_`{|}~"""), ' ', x))
# df.review_description = df.review_description.progress_apply(lambda x: x.replace('Ø›', "", ))

# print("df After punctuation removal", df)

stopWords = list(set(stopwords.words("arabic")))  ## To remove duplictes and return to list again
# Some words needed to work with to will remove
for word in ['Ù„Ø§', 'Ù„ÙƒÙ†', 'ÙˆÙ„ÙƒÙ†']:
    stopWords.remove(word)

# df.review_description = df.review_description.progress_apply(
#     lambda x: " ".join([word for word in x.split() if word not in stopWords]))

emojis = {
    "ğŸ™‚": "ÙŠØ¨ØªØ³Ù…",
    "ğŸ¥°": "Ø­Ø¨",
    "ğŸ’”": "Ù‚Ù„Ø¨ Ø­Ø²ÙŠÙ†",
    "â¤ï¸": "Ø­Ø¨",
    "â¤": "Ø­Ø¨",
    "ğŸ˜": "Ø­Ø¨",
    "ğŸ˜­": "ÙŠØ¨ÙƒÙŠ",
    "ğŸ˜¢": "Ø­Ø²Ù†",
    "ğŸ˜”": "Ø­Ø²Ù†",
    "â™¥": "Ø­Ø¨",
    "ğŸ’œ": "Ø­Ø¨",
    "ğŸ˜…": "ÙŠØ¶Ø­Ùƒ",
    "ğŸ™": "Ø­Ø²ÙŠÙ†",
    "ğŸ’•": "Ø­Ø¨",
    "ğŸ’™": "Ø­Ø¨",
    "ğŸ˜": "Ø­Ø²ÙŠÙ†",
    "ğŸ˜Š": "Ø³Ø¹Ø§Ø¯Ø©",
    "ğŸ‘": "ÙŠØµÙÙ‚",
    "ğŸ‘Œ": "Ø§Ø­Ø³Ù†Øª",
    "ğŸ˜´": "ÙŠÙ†Ø§Ù…",
    "ğŸ˜€": "ÙŠØ¶Ø­Ùƒ",
    "ğŸ˜Œ": "Ø­Ø²ÙŠÙ†",
    "ğŸŒ¹": "ÙˆØ±Ø¯Ø©",
    "ğŸ™ˆ": "Ø­Ø¨",
    "ğŸ˜„": "ÙŠØ¶Ø­Ùƒ",
    "ğŸ˜": "Ù…Ø­Ø§ÙŠØ¯",
    "âœŒ": "Ù…Ù†ØªØµØ±",
    "âœ¨": "Ù†Ø¬Ù…Ù‡",
    "ğŸ¤”": "ØªÙÙƒÙŠØ±",
    "ğŸ˜": "ÙŠØ³ØªÙ‡Ø²Ø¡",
    "ğŸ˜’": "ÙŠØ³ØªÙ‡Ø²Ø¡",
    "ğŸ™„": "Ù…Ù„Ù„",
    "ğŸ˜•": "Ø¹ØµØ¨ÙŠØ©",
    "ğŸ˜ƒ": "ÙŠØ¶Ø­Ùƒ",
    "ğŸŒ¸": "ÙˆØ±Ø¯Ø©",
    "ğŸ˜“": "Ø­Ø²Ù†",
    "ğŸ’": "Ø­Ø¨",
    "ğŸ’—": "Ø­Ø¨",
    "ğŸ˜‘": "Ù…Ù†Ø²Ø¹Ø¬",
    "ğŸ’­": "ØªÙÙƒÙŠØ±",
    "ğŸ˜": "Ø«Ù‚Ø©",
    "ğŸ’›": "Ø­Ø¨",
    "ğŸ˜©": "Ø­Ø²ÙŠÙ†",
    "ğŸ’ª": "Ø¹Ø¶Ù„Ø§Øª",
    "ğŸ‘": "Ù…ÙˆØ§ÙÙ‚",
    "ğŸ™ğŸ»": "Ø±Ø¬Ø§Ø¡ Ø·Ù„Ø¨",
    "ğŸ˜³": "Ù…ØµØ¯ÙˆÙ…",
    "ğŸ‘ğŸ¼": "ØªØµÙÙŠÙ‚",
    "ğŸ¶": "Ù…ÙˆØ³ÙŠÙ‚ÙŠ",
    "ğŸŒš": "ØµÙ…Øª",
    "ğŸ’š": "Ø­Ø¨",
    "ğŸ™": "Ø±Ø¬Ø§Ø¡ Ø·Ù„Ø¨",
    "ğŸ’˜": "Ø­Ø¨",
    "ğŸƒ": "Ø³Ù„Ø§Ù…",
    "â˜º": "ÙŠØ¶Ø­Ùƒ",
    "ğŸ¸": "Ø¶ÙØ¯Ø¹",
    "ğŸ˜¶": "Ù…ØµØ¯ÙˆÙ…",
    "âœŒï¸": "Ù…Ø±Ø­",
    "âœ‹ğŸ»": "ØªÙˆÙ‚Ù",
    "ğŸ˜‰": "ØºÙ…Ø²Ø©",
    "ğŸŒ·": "Ø­Ø¨",
    "ğŸ™ƒ": "Ù…Ø¨ØªØ³Ù…",
    "ğŸ˜«": "Ø­Ø²ÙŠÙ†",
    "ğŸ˜¨": "Ù…ØµØ¯ÙˆÙ…",
    "ğŸ¼ ": "Ù…ÙˆØ³ÙŠÙ‚ÙŠ",
    "ğŸ": "Ù…Ø±Ø­",
    "ğŸ‚": "Ù…Ø±Ø­",
    "ğŸ’Ÿ": "Ø­Ø¨",
    "ğŸ˜ª": "Ø­Ø²Ù†",
    "ğŸ˜†": "ÙŠØ¶Ø­Ùƒ",
    "ğŸ˜£": "Ø§Ø³ØªÙŠØ§Ø¡",
    "â˜ºï¸": "Ø­Ø¨",
    "ğŸ˜±": "ÙƒØ§Ø±Ø«Ø©",
    "ğŸ˜": "ÙŠØ¶Ø­Ùƒ",
    "ğŸ˜–": "Ø§Ø³ØªÙŠØ§Ø¡",
    "ğŸƒğŸ¼": "ÙŠØ¬Ø±ÙŠ",
    "ğŸ˜¡": "ØºØ¶Ø¨",
    "ğŸš¶": "ÙŠØ³ÙŠØ±",
    "ğŸ¤•": "Ù…Ø±Ø¶",
    "â€¼ï¸": "ØªØ¹Ø¬Ø¨",
    "ğŸ•Š": "Ø·Ø§Ø¦Ø±",
    "ğŸ‘ŒğŸ»": "Ø§Ø­Ø³Ù†Øª",
    "â£": "Ø­Ø¨",
    "ğŸ™Š": "Ù…ØµØ¯ÙˆÙ…",
    "ğŸ’ƒ": "Ø³Ø¹Ø§Ø¯Ø© Ù…Ø±Ø­",
    "ğŸ’ƒğŸ¼": "Ø³Ø¹Ø§Ø¯Ø© Ù…Ø±Ø­",
    "ğŸ˜œ": "Ù…Ø±Ø­",
    "ğŸ‘Š": "Ø¶Ø±Ø¨Ø©",
    "ğŸ˜Ÿ": "Ø§Ø³ØªÙŠØ§Ø¡",
    "ğŸ’–": "Ø­Ø¨",
    "ğŸ˜¥": "Ø­Ø²Ù†",
    "ğŸ»": "Ù…ÙˆØ³ÙŠÙ‚ÙŠ",
    "âœ’": "ÙŠÙƒØªØ¨",
    "ğŸš¶ğŸ»": "ÙŠØ³ÙŠØ±",
    "ğŸ’": "Ø§Ù„Ù…Ø§Ø¸",
    "ğŸ˜·": "ÙˆØ¨Ø§Ø¡ Ù…Ø±Ø¶",
    "â˜": "ÙˆØ§Ø­Ø¯",
    "ğŸš¬": "ØªØ¯Ø®ÙŠÙ†",
    "ğŸ’": "ÙˆØ±Ø¯",
    "ğŸŒ": "Ø´Ù…Ø³",
    "ğŸ‘†": "Ø§Ù„Ø§ÙˆÙ„",
    "âš ï¸": "ØªØ­Ø°ÙŠØ±",
    "ğŸ¤—": "Ø§Ø­ØªÙˆØ§Ø¡",
    "âœ–ï¸": "ØºÙ„Ø·",
    "ğŸ“": "Ù…ÙƒØ§Ù†",
    "ğŸ‘¸": "Ù…Ù„ÙƒÙ‡",
    "ğŸ‘‘": "ØªØ§Ø¬",
    "âœ”ï¸": "ØµØ­",
    "ğŸ’Œ": "Ù‚Ù„Ø¨",
    "ğŸ˜²": "Ù…Ù†Ø¯Ù‡Ø´",
    "ğŸ’¦": "Ù…Ø§Ø¡",
    "ğŸš«": "Ø®Ø·Ø§",
    "ğŸ‘ğŸ»": "Ø¨Ø±Ø§ÙÙˆ",
    "ğŸŠ": "ÙŠØ³Ø¨Ø­",
    "ğŸ‘ğŸ»": "ØªÙ…Ø§Ù…",
    "â­•ï¸": "Ø¯Ø§Ø¦Ø±Ù‡ ÙƒØ¨ÙŠØ±Ù‡",
    "ğŸ·": "Ø³Ø§ÙƒØ³ÙÙˆÙ†",
    "ğŸ‘‹": "ØªÙ„ÙˆÙŠØ­ Ø¨Ø§Ù„ÙŠØ¯",
    "âœŒğŸ¼": "Ø¹Ù„Ø§Ù…Ù‡ Ø§Ù„Ù†ØµØ±",
    "ğŸŒ": "Ù…Ø¨ØªØ³Ù…",
    "â¿": "Ø¹Ù‚Ø¯Ù‡ Ù…Ø²Ø¯ÙˆØ¬Ù‡",
    "ğŸ’ªğŸ¼": "Ù‚ÙˆÙŠ",
    "ğŸ“©": "ØªÙˆØ§ØµÙ„ Ù…Ø¹ÙŠ",
    "â˜•ï¸": "Ù‚Ù‡ÙˆÙ‡",
    "ğŸ˜§": "Ù‚Ù„Ù‚ Ùˆ ØµØ¯Ù…Ø©",
    "ğŸ—¨": "Ø±Ø³Ø§Ù„Ø©",
    "â—ï¸": "ØªØ¹Ø¬Ø¨",
    "ğŸ™†ğŸ»": "Ø§Ø´Ø§Ø±Ù‡ Ù…ÙˆØ§ÙÙ‚Ù‡",
    "ğŸ‘¯": "Ø§Ø®ÙˆØ§Øª",
    "Â©": "Ø±Ù…Ø²",
    "ğŸ‘µğŸ½": "Ø³ÙŠØ¯Ù‡ Ø¹Ø¬ÙˆØ²Ù‡",
    "ğŸ£": "ÙƒØªÙƒÙˆØª",
    "ğŸ™Œ": "ØªØ´Ø¬ÙŠØ¹",
    "ğŸ™‡": "Ø´Ø®Øµ ÙŠÙ†Ø­Ù†ÙŠ",
    "ğŸ‘ğŸ½": "Ø§ÙŠØ¯ÙŠ Ù…ÙØªÙˆØ­Ù‡",
    "ğŸ‘ŒğŸ½": "Ø¨Ø§Ù„Ø¸Ø¨Ø·",
    "â‰ï¸": "Ø§Ø³ØªÙ†ÙƒØ§Ø±",
    "âš½ï¸": "ÙƒÙˆØ±Ù‡",
    "ğŸ•¶": "Ø­Ø¨",
    "ğŸˆ": "Ø¨Ø§Ù„ÙˆÙ†",
    "ğŸ€": "ÙˆØ±Ø¯Ù‡",
    "ğŸ’µ": "ÙÙ„ÙˆØ³",
    "ğŸ˜‹": "Ø¬Ø§Ø¦Ø¹",
    "ğŸ˜›": "ÙŠØºÙŠØ¸",
    "ğŸ˜ ": "ØºØ§Ø¶Ø¨",
    "âœğŸ»": "ÙŠÙƒØªØ¨",
    "ğŸŒ¾": "Ø§Ø±Ø²",
    "ğŸ‘£": "Ø§Ø«Ø± Ù‚Ø¯Ù…ÙŠÙ†",
    "âŒ": "Ø±ÙØ¶",
    "ğŸŸ": "Ø·Ø¹Ø§Ù…",
    "ğŸ‘¬": "ØµØ¯Ø§Ù‚Ø©",
    "ğŸ°": "Ø§Ø±Ù†Ø¨",
    "â˜‚": "Ù…Ø·Ø±",
    "âšœ": "Ù…Ù…Ù„ÙƒØ© ÙØ±Ù†Ø³Ø§",
    "ğŸ‘": "Ø®Ø±ÙˆÙ",
    "ğŸ—£": "ØµÙˆØª Ù…Ø±ØªÙØ¹",
    "ğŸ‘ŒğŸ¼": "Ø§Ø­Ø³Ù†Øª",
    "â˜˜": "Ù…Ø±Ø­",
    "ğŸ˜®": "ØµØ¯Ù…Ø©",
    "ğŸ˜¦": "Ù‚Ù„Ù‚",
    "â­•": "Ø§Ù„Ø­Ù‚",
    "âœï¸": "Ù‚Ù„Ù…",
    "â„¹": "Ù…Ø¹Ù„ÙˆÙ…Ø§Øª",
    "ğŸ™ğŸ»": "Ø±ÙØ¶",
    "âšªï¸": "Ù†Ø¶Ø§Ø±Ø© Ù†Ù‚Ø§Ø¡",
    "ğŸ¤": "Ø­Ø²Ù†",
    "ğŸ’«": "Ù…Ø±Ø­",
    "ğŸ’": "Ø­Ø¨",
    "ğŸ”": "Ø·Ø¹Ø§Ù…",
    "â¤ï¸": "Ø­Ø¨",
    "âœˆï¸": "Ø³ÙØ±",
    "ğŸƒğŸ»â€â™€ï¸": "ÙŠØ³ÙŠØ±",
    "ğŸ³": "Ø°ÙƒØ±",
    "ğŸ¤": "Ù…Ø§ÙŠÙƒ ØºÙ†Ø§Ø¡",
    "ğŸ¾": "ÙƒØ±Ù‡",
    "ğŸ”": "Ø¯Ø¬Ø§Ø¬Ø©",
    "ğŸ™‹": "Ø³Ø¤Ø§Ù„",
    "ğŸ“®": "Ø¨Ø­Ø±",
    "ğŸ’‰": "Ø¯ÙˆØ§Ø¡",
    "ğŸ™ğŸ¼": "Ø±Ø¬Ø§Ø¡ Ø·Ù„Ø¨",
    "ğŸ’‚ğŸ¿ ": "Ø­Ø§Ø±Ø³",
    "ğŸ¬": "Ø³ÙŠÙ†Ù…Ø§",
    "â™¦ï¸": "Ù…Ø±Ø­",
    "ğŸ’¡": "Ù‚ÙƒØ±Ø©",
    "â€¼": "ØªØ¹Ø¬Ø¨",
    "ğŸ‘¼": "Ø·ÙÙ„",
    "ğŸ”‘": "Ù…ÙØªØ§Ø­",
    "â™¥ï¸": "Ø­Ø¨",
    "ğŸ•‹": "ÙƒØ¹Ø¨Ø©",
    "ğŸ“": "Ø¯Ø¬Ø§Ø¬Ø©",
    "ğŸ’©": "Ù…Ø¹ØªØ±Ø¶",
    "ğŸ‘½": "ÙØ¶Ø§Ø¦ÙŠ",
    "â˜”ï¸": "Ù…Ø·Ø±",
    "ğŸ·": "Ø¹ØµÙŠØ±",
    "ğŸŒŸ": "Ù†Ø¬Ù…Ø©",
    "â˜ï¸": "Ø³Ø­Ø¨",
    "ğŸ‘ƒ": "Ù…Ø¹ØªØ±Ø¶",
    "ğŸŒº": "Ù…Ø±Ø­",
    "ğŸ”ª": "Ø³ÙƒÙŠÙ†Ø©",
    "â™¨": "Ø³Ø®ÙˆÙ†ÙŠØ©",
    "ğŸ‘ŠğŸ¼": "Ø¶Ø±Ø¨",
    "âœ": "Ù‚Ù„Ù…",
    "ğŸš¶ğŸ¾â€â™€ï¸": "ÙŠØ³ÙŠØ±",
    "ğŸ‘Š": "Ø¶Ø±Ø¨Ø©",
    "â—¾ï¸": "ÙˆÙ‚Ù",
    "ğŸ˜š": "Ø­Ø¨",
    "ğŸ”¸": "Ù…Ø±Ø­",
    "ğŸ‘ğŸ»": "Ù„Ø§ ÙŠØ¹Ø¬Ø¨Ù†ÙŠ",
    "ğŸ‘ŠğŸ½": "Ø¶Ø±Ø¨Ø©",
    "ğŸ˜™": "Ø­Ø¨",
    "ğŸ¥": "ØªØµÙˆÙŠØ±",
    "ğŸ‘‰": "Ø¬Ø°Ø¨ Ø§Ù†ØªØ¨Ø§Ù‡",
    "ğŸ‘ğŸ½": "ÙŠØµÙÙ‚",
    "ğŸ’ªğŸ»": "Ø¹Ø¶Ù„Ø§Øª",
    "ğŸ´": "Ø§Ø³ÙˆØ¯",
    "ğŸ”¥": "Ø­Ø±ÙŠÙ‚",
    "ğŸ˜¬": "Ø¹Ø¯Ù… Ø§Ù„Ø±Ø§Ø­Ø©",
    "ğŸ‘ŠğŸ¿": "ÙŠØ¶Ø±Ø¨",
    "ğŸŒ¿": "ÙˆØ±Ù‚Ù‡ Ø´Ø¬Ø±Ù‡",
    "âœ‹ğŸ¼": "ÙƒÙ Ø§ÙŠØ¯",
    "ğŸ‘": "Ø§ÙŠØ¯ÙŠ Ù…ÙØªÙˆØ­Ù‡",
    "â˜ ï¸": "ÙˆØ¬Ù‡ Ù…Ø±Ø¹Ø¨",
    "ğŸ‰": "ÙŠÙ‡Ù†Ø¦",
    "ğŸ”•": "ØµØ§Ù…Øª",
    "ğŸ˜¿": "ÙˆØ¬Ù‡ Ø­Ø²ÙŠÙ†",
    "â˜¹ï¸": "ÙˆØ¬Ù‡ ÙŠØ§Ø¦Ø³",
    "ğŸ˜˜": "Ø­Ø¨",
    "ğŸ˜°": "Ø®ÙˆÙ Ùˆ Ø­Ø²Ù†",
    "ğŸŒ¼": "ÙˆØ±Ø¯Ù‡",
    "ğŸ’‹": "Ø¨ÙˆØ³Ù‡",
    "ğŸ‘‡": "Ù„Ø§Ø³ÙÙ„",
    "â£ï¸": "Ø­Ø¨",
    "ğŸ§": "Ø³Ù…Ø§Ø¹Ø§Øª",
    "ğŸ“": "ÙŠÙƒØªØ¨",
    "ğŸ˜‡": "Ø¯Ø§ÙŠØ®",
    "ğŸ˜ˆ": "Ø±Ø¹Ø¨",
    "ğŸƒ": "ÙŠØ¬Ø±ÙŠ",
    "âœŒğŸ»": "Ø¹Ù„Ø§Ù…Ù‡ Ø§Ù„Ù†ØµØ±",
    "ğŸ”«": "ÙŠØ¶Ø±Ø¨",
    "â—ï¸": "ØªØ¹Ø¬Ø¨",
    "ğŸ‘": "ØºÙŠØ± Ù…ÙˆØ§ÙÙ‚",
    "ğŸ”": "Ù‚ÙÙ„",
    "ğŸ‘ˆ": "Ù„Ù„ÙŠÙ…ÙŠÙ†",
    "â„¢": "Ø±Ù…Ø²",
    "ğŸš¶ğŸ½": "ÙŠØªÙ…Ø´ÙŠ",
    "ğŸ˜¯": "Ù…ØªÙØ§Ø¬Ø£",
    "âœŠ": "ÙŠØ¯ Ù…ØºÙ„Ù‚Ù‡",
    "ğŸ˜»": "Ø§Ø¹Ø¬Ø§Ø¨",
    "ğŸ™‰": "Ù‚Ø±Ø¯",
    "ğŸ‘§": "Ø·ÙÙ„Ù‡ ØµØºÙŠØ±Ù‡",
    "ğŸ”´": "Ø¯Ø§Ø¦Ø±Ù‡ Ø­Ù…Ø±Ø§Ø¡",
    "ğŸ’ªğŸ½": "Ù‚ÙˆÙ‡",
    "ğŸ’¤": "ÙŠÙ†Ø§Ù…",
    "ğŸ‘€": "ÙŠÙ†Ø¸Ø±",
    "âœğŸ»": "ÙŠÙƒØªØ¨",
    "â„ï¸": "ØªÙ„Ø¬",
    "ğŸ’€": "Ø±Ø¹Ø¨",
    "ğŸ˜¤": "ÙˆØ¬Ù‡ Ø¹Ø§Ø¨Ø³",
    "ğŸ–‹": "Ù‚Ù„Ù…",
    "ğŸ©": "ÙƒØ§Ø¨",
    "â˜•ï¸": "Ù‚Ù‡ÙˆÙ‡",
    "ğŸ˜¹": "Ø¶Ø­Ùƒ",
    "ğŸ’“": "Ø­Ø¨",
    "â˜„ï¸ ": "Ù†Ø§Ø±",
    "ğŸ‘»": "Ø±Ø¹Ø¨",
    "â": "Ø®Ø·Ø¡",
    "ğŸ¤®": "Ø­Ø²Ù†",
    'ğŸ»': "Ø§Ø­Ù…Ø±"
}

emoticons_to_emoji = {
    ":)": "ğŸ™‚",
    ":(": "ğŸ™",
    "xD": "ğŸ˜†",
    ":=(": "ğŸ˜­",
    ":'(": "ğŸ˜¢",
    ":'â€‘(": "ğŸ˜¢",
    "XD": "ğŸ˜‚",
    ":D": "ğŸ™‚",
    "â™¬": "Ù…ÙˆØ³ÙŠÙ‚ÙŠ",
    "â™¡": "â¤",
    "â˜»": "ğŸ™‚",
}


def checkemojie(text):
    emojistext = []
    for char in text:
        if any(emoji.distinct_emoji_list(char)) and char in emojis.keys():
            emojistext.append(emojis[emoji.distinct_emoji_list(char)[0]])
    return " ".join(emojistext)


def emojiTextTransform(text):
    cleantext = re.sub(r'[^\w\s]', '', text)
    return cleantext + " " + checkemojie(text)


def detect_language(input_string):
    # Define Unicode ranges for Arabic and English characters
    arabic_range = (0x0600, 0x06FF)
    english_range = (0x0020, 0x007E)

    # Check if the string contains Arabic characters
    arabic_chars = any(ord(char) in range(arabic_range[0], arabic_range[1] + 1) for char in input_string)

    # Check if the string contains English characters
    english_chars = any(ord(char) in range(english_range[0], english_range[1] + 1) for char in input_string)

    if arabic_chars and not english_chars:
        return "Arabic"
    elif english_chars and not arabic_chars:
        return "English"
    else:
        return "Mixed"


def translate_english_to_arabic(input_string):
    # Define Unicode ranges for Arabic and English characters
    listOfWords = input_string.split()
    arabic_range = (0x0600, 0x06FF)
    english_range = (0x0020, 0x007E)

    translator = Translator()

    for index, word in enumerate(listOfWords):
        if arabic_range[0] <= ord(word[0]) <= arabic_range[1]:
            continue
        else:
            while True:
                try:
                    translatedWord = translator.translate(word, dest='ar').text
                    break
                except Exception as e:
                    if "timed out" in str(e).lower():
                        time.sleep(1)
            listOfWords[index] = translatedWord
    returnedString = ' '.join(listOfWords)
    return returnedString


df.review_description = df.review_description.progress_apply(lambda x: emojiTextTransform(x))

# df.review_description = df.review_description.progress_apply(
#     lambda x: ''.join([word for word in x if not word.isdigit()]))

df.review_description = df.review_description.progress_apply(lambda x: translate_english_to_arabic(x))

df.review_description = df.review_description.progress_apply(
    lambda x: " ".join([ArabicLightStemmer().light_stem(word) for word in x.split()]))

df.to_csv('train_dataset_preprocessed.csv', encoding='utf-8-sig')
